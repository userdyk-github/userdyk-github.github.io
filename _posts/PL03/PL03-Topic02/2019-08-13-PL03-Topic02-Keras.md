---
layout : post
title : PL03-Topic02, Keras
categories: [PL03-Topic02]
comments : true
tags : [PL03-Topic02]
---
[Back to the previous page](https://userdyk-github.github.io/pl03/PL03-Libraries.html) <br>
List of posts to read before reading this article
- <a href='https://userdyk-github.github.io/'>post1</a>
- <a href='https://userdyk-github.github.io/'>post2</a>
- <a href='https://userdyk-github.github.io/'>post3</a>

---

## Contents
{:.no_toc}

* ToC
{:toc}

<hr class="division1">

## **An Introduction to Deep Learning and Keras**

### ***A Sneak Peek into the Keras Framework***

```python
# Import required packages 
from keras.models import Sequential
from keras.layers import Dense
import numpy as np

# Getting the data ready 
# Generate train dummy data for 1000 Students and dummy test for 500
# Columns :Age, Hours of Study &Avg Previous test scores 
np.random.seed(2018)  #Setting seed for reproducibility 
train_data, test_data = np.random.random((1000, 3)), np.random.random((500, 3))

# Generate dummy results for 1000 students : Whether Passed (1) or Failed (0) 
train_labels = np.random.randint(2, size=(1000, 1))
test_labels = np.random.randint(2, size=(500, 1))

# Defining the model structure with the required layers, 
# of neurons, activation function and optimizers
model = Sequential() 
model.add(Dense(5, input_dim=3, activation='relu'))
model.add(Dense(4, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(train_data, train_labels, batch_size=32, epochs=3)
```
<details markdown="1">
<summary class='jb-small' style="color:blue">TRAINING RESULT</summary>
<hr class='division3'>
```
Epoch 1/3
1000/1000 [==============================] - 1s 1ms/step - loss: 0.6939 - acc: 0.4870
Epoch 2/3
1000/1000 [==============================] - 0s 41us/step - loss: 0.6934 - acc: 0.4830
Epoch 3/3
1000/1000 [==============================] - 0s 39us/step - loss: 0.6933 - acc: 0.4880
```
<hr class='division3'>
</details>
<details markdown="1">
<summary class='jb-small' style="color:blue">EVALUATION</summary>
<hr class='division3'>
```python
results = model.evaluate(test_data, test_labels)
for i in range(len(model.metrics_names)):
    print(model.metrics_names[i]," : ", results[i])
```
`OUTPUT`
```
500/500 [==============================] - 0s 813us/step
loss  :  0.692422465801239
acc  :  0.5200000002384185
```
<hr class='division3'>
</details>


<br><br><br>
<hr class="division2">

## **Keras in Action**

### ***Putting All the Building Blocks Together***

```python
# Import required packages 
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Activation
from keras.datasets import boston_housing

#Download the data using Keras; this will need an active internet connection
(x_train, y_train), (x_test, y_test) = boston_housing.load_data()


#Extract the last 100 rows from the training data to create the validation datasets. 
x_val = x_train[300:,]       # last 300 row
y_val = y_train[300:,]       # last 300 row

#Define the model architecture
model = Sequential()
model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))
model.add(Dense(6, kernel_initializer='normal', activation='relu'))
model.add(Dense(1, kernel_initializer='normal'))

# Compile model
model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_percentage_error'])

#Train the model
model.fit(x_train, y_train, batch_size=32, epochs=3, validation_data=(x_val,y_val))
```
<details markdown="1">
<summary class='jb-small' style="color:blue">TRAINING RESULT</summary>
<hr class='division3'>
```
Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz
57344/57026 [==============================] - 0s 2us/step

Train on 404 samples, validate on 104 samples
Epoch 1/3
404/404 [==============================] - 1s 2ms/step - loss: 580.9334 - mean_absolute_percentage_error: 99.4362 - val_loss: 662.7088 - val_mean_absolute_percentage_error: 98.0074
Epoch 2/3
404/404 [==============================] - 0s 51us/step - loss: 554.0448 - mean_absolute_percentage_error: 95.8691 - val_loss: 618.2133 - val_mean_absolute_percentage_error: 93.0662
Epoch 3/3
404/404 [==============================] - 0s 50us/step - loss: 492.5111 - mean_absolute_percentage_error: 87.4437 - val_loss: 520.5322 - val_mean_absolute_percentage_error: 81.4210
```
<hr class='division3'>
</details>
<details markdown="1">
<summary class='jb-small' style="color:blue">EVALUATION</summary>
<hr class='division3'>
```python
results = model.evaluate(x_test, y_test)
for i in range(len(model.metrics_names)):
    print(model.metrics_names[i]," : ", results[i])
```
`OUTPUT`
```
102/102 [==============================] - 0s 62us/step
loss  :  463.09825942095586
mean_absolute_percentage_error  :  78.82570214365043
```
<hr class='division3'>
</details>
<details markdown="1">
<summary class='jb-small' style="color:blue">RETRAINING(after tuning fitting parameters)</summary>
<hr class='division3'>
```python
#Train the model 
model.fit(x_train, y_train, batch_size=32, epochs=30, validation_data=(x_val,y_val))
```
`OUTPUT`
```
Train on 404 samples, validate on 104 samples
Epoch 1/30
404/404 [==============================] - 0s 58us/step - loss: 379.4086 - mean_absolute_percentage_error: 70.2558 - val_loss: 360.9293 - val_mean_absolute_percentage_error: 59.3759
Epoch 2/30
404/404 [==============================] - 0s 47us/step - loss: 228.6982 - mean_absolute_percentage_error: 48.1161 - val_loss: 198.9693 - val_mean_absolute_percentage_error: 40.2195
Epoch 3/30
404/404 [==============================] - 0s 49us/step - loss: 137.9041 - mean_absolute_percentage_error: 43.9592 - val_loss: 143.6277 - val_mean_absolute_percentage_error: 42.3353
Epoch 4/30
404/404 [==============================] - 0s 50us/step - loss: 128.0068 - mean_absolute_percentage_error: 48.4147 - val_loss: 136.8944 - val_mean_absolute_percentage_error: 40.8082
Epoch 5/30
404/404 [==============================] - 0s 55us/step - loss: 118.3841 - mean_absolute_percentage_error: 44.0519 - val_loss: 133.1419 - val_mean_absolute_percentage_error: 37.5794
Epoch 6/30
404/404 [==============================] - 0s 49us/step - loss: 111.5623 - mean_absolute_percentage_error: 40.6460 - val_loss: 128.8092 - val_mean_absolute_percentage_error: 35.8778
Epoch 7/30
404/404 [==============================] - 0s 50us/step - loss: 105.6107 - mean_absolute_percentage_error: 39.3712 - val_loss: 121.8723 - val_mean_absolute_percentage_error: 35.2191
Epoch 8/30
404/404 [==============================] - 0s 60us/step - loss: 100.5365 - mean_absolute_percentage_error: 38.5076 - val_loss: 116.7530 - val_mean_absolute_percentage_error: 34.0602
Epoch 9/30
404/404 [==============================] - 0s 55us/step - loss: 95.6473 - mean_absolute_percentage_error: 36.4750 - val_loss: 112.9952 - val_mean_absolute_percentage_error: 32.6358
Epoch 10/30
404/404 [==============================] - 0s 56us/step - loss: 91.3528 - mean_absolute_percentage_error: 35.8936 - val_loss: 107.6109 - val_mean_absolute_percentage_error: 32.4268
Epoch 11/30
404/404 [==============================] - 0s 62us/step - loss: 86.8670 - mean_absolute_percentage_error: 34.5687 - val_loss: 105.0734 - val_mean_absolute_percentage_error: 30.8377
Epoch 12/30
404/404 [==============================] - 0s 57us/step - loss: 83.8678 - mean_absolute_percentage_error: 33.1729 - val_loss: 100.9976 - val_mean_absolute_percentage_error: 30.1347
Epoch 13/30
404/404 [==============================] - 0s 79us/step - loss: 80.3338 - mean_absolute_percentage_error: 32.9414 - val_loss: 98.0269 - val_mean_absolute_percentage_error: 29.1839
Epoch 14/30
404/404 [==============================] - 0s 49us/step - loss: 77.0266 - mean_absolute_percentage_error: 31.3633 - val_loss: 96.0304 - val_mean_absolute_percentage_error: 28.0592
Epoch 15/30
404/404 [==============================] - 0s 69us/step - loss: 74.5713 - mean_absolute_percentage_error: 30.6367 - val_loss: 93.4559 - val_mean_absolute_percentage_error: 27.4387
Epoch 16/30
404/404 [==============================] - 0s 76us/step - loss: 72.4605 - mean_absolute_percentage_error: 30.5300 - val_loss: 90.2561 - val_mean_absolute_percentage_error: 27.5172
Epoch 17/30
404/404 [==============================] - 0s 56us/step - loss: 70.2668 - mean_absolute_percentage_error: 30.4674 - val_loss: 89.6360 - val_mean_absolute_percentage_error: 26.2286
Epoch 18/30
404/404 [==============================] - 0s 59us/step - loss: 69.0524 - mean_absolute_percentage_error: 28.2962 - val_loss: 89.3691 - val_mean_absolute_percentage_error: 25.0894
Epoch 19/30
404/404 [==============================] - 0s 59us/step - loss: 67.1439 - mean_absolute_percentage_error: 28.7645 - val_loss: 86.4003 - val_mean_absolute_percentage_error: 25.7927
Epoch 20/30
404/404 [==============================] - 0s 65us/step - loss: 66.1058 - mean_absolute_percentage_error: 29.1919 - val_loss: 85.8313 - val_mean_absolute_percentage_error: 25.0127
Epoch 21/30
404/404 [==============================] - 0s 55us/step - loss: 65.2683 - mean_absolute_percentage_error: 27.9101 - val_loss: 85.7227 - val_mean_absolute_percentage_error: 24.2154
Epoch 22/30
404/404 [==============================] - 0s 57us/step - loss: 64.3430 - mean_absolute_percentage_error: 28.2435 - val_loss: 84.4628 - val_mean_absolute_percentage_error: 24.4009
Epoch 23/30
404/404 [==============================] - 0s 56us/step - loss: 63.5753 - mean_absolute_percentage_error: 27.9445 - val_loss: 83.9498 - val_mean_absolute_percentage_error: 24.2201
Epoch 24/30
404/404 [==============================] - 0s 62us/step - loss: 62.9955 - mean_absolute_percentage_error: 28.0562 - val_loss: 83.1876 - val_mean_absolute_percentage_error: 24.3564
Epoch 25/30
404/404 [==============================] - 0s 52us/step - loss: 62.5542 - mean_absolute_percentage_error: 27.7791 - val_loss: 83.8650 - val_mean_absolute_percentage_error: 23.6271
Epoch 26/30
404/404 [==============================] - 0s 53us/step - loss: 62.1328 - mean_absolute_percentage_error: 27.1743 - val_loss: 82.4939 - val_mean_absolute_percentage_error: 24.0875
Epoch 27/30
404/404 [==============================] - 0s 58us/step - loss: 61.6133 - mean_absolute_percentage_error: 27.6719 - val_loss: 82.2328 - val_mean_absolute_percentage_error: 23.8878
Epoch 28/30
404/404 [==============================] - 0s 61us/step - loss: 60.8626 - mean_absolute_percentage_error: 26.9424 - val_loss: 82.7886 - val_mean_absolute_percentage_error: 23.2897
Epoch 29/30
404/404 [==============================] - 0s 54us/step - loss: 60.6314 - mean_absolute_percentage_error: 26.1994 - val_loss: 81.6793 - val_mean_absolute_percentage_error: 23.6167
Epoch 30/30
404/404 [==============================] - 0s 52us/step - loss: 60.5237 - mean_absolute_percentage_error: 27.4995 - val_loss: 81.5046 - val_mean_absolute_percentage_error: 23.4413
<keras.callbacks.History at 0x7fd199e50c18>
```
<hr class='division3'>
</details>
<details markdown="1">
<summary class='jb-small' style="color:blue">EVALUATION2</summary>
<hr class='division3'>
```python
results = model.evaluate(x_test, y_test)
for i in range(len(model.metrics_names)):
    print(model.metrics_names[i]," : ", results[i])
```
`OUTPUT`
```
102/102 [==============================] - 0s 92us/step
loss  :  65.75437209185432
mean_absolute_percentage_error  :  31.099634806315105
```
<hr class='division3'>
</details>
<br><br><br>

<hr class="division2">

## **Deep Neural Networks for Supervised Learning: Regression**

### ***Exploring the Data***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

---

### ***Data Engineering***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

---

### ***Defining Model Baseline Performance***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

---

### ***Designing the DNN***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>


<hr class="division2">

## **Deep Neural Networks for Supervised Learning: Classification**

### ***Exploring the Data***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

---

### ***Data Engineering***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

---

### ***Defining Model Baseline Accuracy***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

---

### ***Designing the DNN for Classification***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

---

### ***Revisiting the Data***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

---

### ***DNNs for Classification with Improved Data***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>


<hr class="division2">

## **Tuning and Deploying Deep Neural Networks**

### ***What Is Regularization***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

---

### ***Hyperparameter Tuning***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

---


### ***Model Deployment***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>


<hr class="division2">

## **The Path Ahead**

### ***Whatâ€™s Next for DL Expertise***

```python
```
<details markdown="1">
<summary class='jb-small' style="color:blue">OUTPUT</summary>
<hr class='division3'>
<hr class='division3'>
</details>
<br><br><br>

<hr class="division1">

List of posts followed by this article
- [post1](https://userdyk-github.github.io/)
- <a href='https://userdyk-github.github.io/'>post2</a>
- <a href='https://userdyk-github.github.io/'>post3</a>

---

Reference
- Jojo Moolayil, Learn Keras for Deep Neural Networks, 2019
- <a href='https://userdyk-github.github.io/'>post2</a>
- <a href='https://userdyk-github.github.io/'>post3</a>

---





